import os
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

# .env dosyasÄ±ndan API anahtarÄ±nÄ± yÃ¼kle
load_dotenv()
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")

# PDF dosya yolu
PDF_PATH = "hukuk_metni.pdf"

def ingest_pdf():
    # PDF'i sayfa sayfa yÃ¼kle
    loader = PyPDFLoader(PDF_PATH)
    pages = loader.load()

    # SayfalarÄ± kÃ¼Ã§Ã¼k parÃ§alara bÃ¶l (token sayÄ±sÄ± < 300K garantili)
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=700,       # ğŸ”§ Her parÃ§a max 700 karakter
        chunk_overlap=100     # ğŸ” Ã–nceki parÃ§a ile 100 karakter Ã¶rtÃ¼ÅŸme
    )
    chunks = text_splitter.split_documents(pages)

    print(f"âœ… Toplam {len(chunks)} parÃ§a Ã¼retildi. Embed ediliyor...")

    # OpenAI embedding
    embedding = OpenAIEmbeddings()

    # Chroma vektÃ¶r veri tabanÄ± oluÅŸtur
    vectorstore = Chroma.from_documents(
        documents=chunks,
        embedding=embedding,
        persist_directory="./db"
    )
    vectorstore.persist()

    print("âœ… VektÃ¶r veri tabanÄ± baÅŸarÄ±yla oluÅŸturuldu.")

if __name__ == "__main__":
    ingest_pdf()
